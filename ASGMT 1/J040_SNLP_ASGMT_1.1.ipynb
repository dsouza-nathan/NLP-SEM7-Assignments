{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gensim\nimport gensim.downloader as api\nfrom gensim.models import Word2Vec\nfrom pprint import pprint","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:03:06.218684Z","iopub.execute_input":"2025-07-20T05:03:06.218946Z","iopub.status.idle":"2025-07-20T05:03:06.223173Z","shell.execute_reply.started":"2025-07-20T05:03:06.218927Z","shell.execute_reply":"2025-07-20T05:03:06.222351Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"print(\"Loading pretrained model...\")\npretrained_model = api.load(\"word2vec-google-news-300\")\nprint(\"Loaded Google News Word2Vec model!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:03:06.224571Z","iopub.execute_input":"2025-07-20T05:03:06.224848Z","iopub.status.idle":"2025-07-20T05:03:50.208078Z","shell.execute_reply.started":"2025-07-20T05:03:06.224828Z","shell.execute_reply":"2025-07-20T05:03:50.207335Z"}},"outputs":[{"name":"stdout","text":"Loading pretrained model...\nLoaded Google News Word2Vec model!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"words = ['science', 'coffee', 'music', 'apple', 'teacher']\n\nprint(\"\\n--- Similar Words from Pretrained Model ---\")\nfor word in words:\n    print(f\"\\nTop 5 similar words to '{word}':\")\n    for similar, score in pretrained_model.most_similar(word, topn=5):\n        print(f\"  {similar} ({score:.4f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:03:50.208927Z","iopub.execute_input":"2025-07-20T05:03:50.209228Z","iopub.status.idle":"2025-07-20T05:03:52.424103Z","shell.execute_reply.started":"2025-07-20T05:03:50.209208Z","shell.execute_reply":"2025-07-20T05:03:52.423373Z"}},"outputs":[{"name":"stdout","text":"\n--- Similar Words from Pretrained Model ---\n\nTop 5 similar words to 'science':\n  faith_Jezierski (0.6965)\n  sciences (0.6821)\n  biology (0.6776)\n  scientific (0.6535)\n  mathematics (0.6301)\n\nTop 5 similar words to 'coffee':\n  coffees (0.7213)\n  gourmet_coffee (0.7057)\n  Coffee (0.6900)\n  o_joe (0.6891)\n  Starbucks_coffee (0.6875)\n\nTop 5 similar words to 'music':\n  classical_music (0.7198)\n  jazz (0.6835)\n  Music (0.6596)\n  Without_Donny_Kirshner (0.6416)\n  songs (0.6396)\n\nTop 5 similar words to 'apple':\n  apples (0.7204)\n  pear (0.6451)\n  fruit (0.6410)\n  berry (0.6302)\n  pears (0.6134)\n\nTop 5 similar words to 'teacher':\n  teachers (0.7434)\n  Teacher (0.7094)\n  guidance_counselor (0.6960)\n  elementary (0.6791)\n  PE_teacher (0.6539)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"print(\"\\n--- Word Analogies (Pretrained Model) ---\")\n\nanalogies = [\n    ('king', 'man', 'woman'),    # queen\n    ('paris', 'france', 'italy'),  # rome\n    ('doctor', 'hospital', 'school')  # teacher\n]\n\nfor a, b, c in analogies:\n    result = pretrained_model.most_similar(positive=[a, c], negative=[b], topn=1)\n    print(f\"{a} - {b} + {c} ≈ {result[0][0]} ({result[0][1]:.4f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:03:52.425554Z","iopub.execute_input":"2025-07-20T05:03:52.425799Z","iopub.status.idle":"2025-07-20T05:03:53.100440Z","shell.execute_reply.started":"2025-07-20T05:03:52.425780Z","shell.execute_reply":"2025-07-20T05:03:53.099640Z"}},"outputs":[{"name":"stdout","text":"\n--- Word Analogies (Pretrained Model) ---\nking - man + woman ≈ queen (0.7118)\nparis - france + italy ≈ lohan (0.5070)\ndoctor - hospital + school ≈ guidance_counselor (0.5970)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Sample custom corpus\nsentences = [\n    [\"machine\", \"learning\", \"is\", \"fun\"],\n    [\"deep\", \"learning\", \"uses\", \"neural\", \"networks\"],\n    [\"natural\", \"language\", \"processing\", \"with\", \"word2vec\"],\n    [\"word\", \"embeddings\", \"capture\", \"semantic\", \"meaning\"],\n    [\"vectors\", \"are\", \"mathematical\", \"representations\"]\n]\n\n# Train model\ncustom_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\nprint(\"\\nTrained custom Word2Vec model.\")\n\n\nprint(\"\\n--- Similar Words from Custom Model ---\")\ntest_words = [\"learning\", \"word2vec\", \"vectors\"]\nfor word in test_words:\n    print(f\"\\nTop similar words to '{word}':\")\n    pprint(custom_model.wv.most_similar(word, topn=3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:03:53.101212Z","iopub.execute_input":"2025-07-20T05:03:53.101427Z","iopub.status.idle":"2025-07-20T05:03:53.117065Z","shell.execute_reply.started":"2025-07-20T05:03:53.101404Z","shell.execute_reply":"2025-07-20T05:03:53.116361Z"}},"outputs":[{"name":"stdout","text":"\nTrained custom Word2Vec model.\n\n--- Similar Words from Custom Model ---\n\nTop similar words to 'learning':\n[('uses', 0.21883946657180786),\n ('embeddings', 0.21617142856121063),\n ('language', 0.0931052565574646)]\n\nTop similar words to 'word2vec':\n[('meaning', 0.2529045045375824),\n ('deep', 0.14257237315177917),\n ('representations', 0.13725489377975464)]\n\nTop similar words to 'vectors':\n[('natural', 0.17825926840305328),\n ('mathematical', 0.13149219751358032),\n ('word', 0.07499314099550247)]\n","output_type":"stream"}],"execution_count":11}]}